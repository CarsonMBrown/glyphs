Image input directory: dataset\glyphs\eval\generated\cropped
transform Compose(
    Resize(size=27, interpolation=bilinear, max_size=28, antialias=None)
    Pad(padding=27, fill=0, padding_mode=constant)
    CenterCrop(size=(28, 28))
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
Input Vector Size: None
Image input directory: dataset\glyphs\train\generated\cropped
transform Compose(
    Resize(size=27, interpolation=bilinear, max_size=28, antialias=None)
    Pad(padding=27, fill=0, padding_mode=constant)
    CenterCrop(size=(28, 28))
    RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)
    RandomAffine(degrees=[-20.0, 20.0], translate=(0.1, 0.1), scale=(0.9, 1.1))
    ColorJitter(brightness=[0.8, 1.2], contrast=[0.8, 1.2], saturation=None, hue=None)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
Training set has 25000 instances
EPOCH 0:
  batch 100 loss: 3.120362603664398
  batch 200 loss: 2.8525861859321595
  batch 300 loss: 2.725964324474335
LOSS train 2.725964324474335 valid 2.5136654376983643
PRECISION 0.2219941618260937 RECALL 0.2854034810126582 FSCORE 0.22994483003528093
EPOCH 1:
  batch 100 loss: 2.5560438799858094
  batch 200 loss: 2.458478779792786
  batch 300 loss: 2.3234842300415037
LOSS train 2.3234842300415037 valid 2.009308099746704
PRECISION 0.3787357548426225 RECALL 0.442246835443038 FSCORE 0.38460853991999244
EPOCH 2:
  batch 100 loss: 2.196328971385956
  batch 200 loss: 2.147067322731018
  batch 300 loss: 2.0437300288677216
LOSS train 2.0437300288677216 valid 1.7230514287948608
PRECISION 0.49357554447793767 RECALL 0.5124604430379747 FSCORE 0.4745840344123415
EPOCH 3:
  batch 100 loss: 1.9446971392631531
  batch 200 loss: 1.8982912302017212
  batch 300 loss: 1.8579420852661133
LOSS train 1.8579420852661133 valid 1.5898374319076538
PRECISION 0.5380699101575289 RECALL 0.5476661392405063 FSCORE 0.5141639743964918
EPOCH 4:
  batch 100 loss: 1.7922407174110413
  batch 200 loss: 1.761532155275345
  batch 300 loss: 1.705232756137848
LOSS train 1.705232756137848 valid 1.4688026905059814
PRECISION 0.5838499766552633 RECALL 0.5801028481012658 FSCORE 0.5554155550727351
EPOCH 5:
  batch 100 loss: 1.6579145562648774
  batch 200 loss: 1.6359871327877045
  batch 300 loss: 1.6020957100391389
LOSS train 1.6020957100391389 valid 1.3957911729812622
PRECISION 0.6084144807592196 RECALL 0.5965189873417721 FSCORE 0.5748841119593701
EPOCH 6:
  batch 100 loss: 1.5802469515800477
  batch 200 loss: 1.523254736661911
  batch 300 loss: 1.5152387940883636
LOSS train 1.5152387940883636 valid 1.342142105102539
PRECISION 0.6310482131769014 RECALL 0.6216376582278481 FSCORE 0.5995156471873203
EPOCH 7:
  batch 100 loss: 1.4901079869270324
  batch 200 loss: 1.4642967367172242
  batch 300 loss: 1.4468272793293
LOSS train 1.4468272793293 valid 1.2996561527252197
PRECISION 0.6468111030363799 RECALL 0.6301424050632911 FSCORE 0.614188995419967
EPOCH 8:
  batch 100 loss: 1.4104441744089127
  batch 200 loss: 1.4046765112876891
  batch 300 loss: 1.396203773021698
LOSS train 1.396203773021698 valid 1.2564997673034668
PRECISION 0.6515784422217663 RECALL 0.6331091772151899 FSCORE 0.6184821537167198
EPOCH 9:
  batch 100 loss: 1.3788854455947877
  batch 200 loss: 1.3634785372018814
  batch 300 loss: 1.352390546798706
LOSS train 1.352390546798706 valid 1.2411391735076904
PRECISION 0.664229526742906 RECALL 0.6422072784810127 FSCORE 0.6260191406395937
EPOCH 10:
  batch 100 loss: 1.3387490224838257
  batch 200 loss: 1.3121406108140945
  batch 300 loss: 1.3137070065736771
LOSS train 1.3137070065736771 valid 1.2071994543075562
PRECISION 0.6744450115197742 RECALL 0.6493275316455697 FSCORE 0.6364585897751402
EPOCH 11:
  batch 100 loss: 1.3095043647289275
  batch 200 loss: 1.28258336186409
  batch 300 loss: 1.2807322359085083
LOSS train 1.2807322359085083 valid 1.201917290687561
PRECISION 0.6771240434363459 RECALL 0.6524920886075949 FSCORE 0.6387866590357267
EPOCH 12:
  batch 100 loss: 1.271255698800087
  batch 200 loss: 1.2512550973892211
  batch 300 loss: 1.2359735131263734
LOSS train 1.2359735131263734 valid 1.1879541873931885
PRECISION 0.6837384239134634 RECALL 0.6552610759493671 FSCORE 0.6438772473791654
EPOCH 13:
  batch 100 loss: 1.2598251897096633
  batch 200 loss: 1.2325631093978882
  batch 300 loss: 1.2316461163759231
LOSS train 1.2316461163759231 valid 1.1574965715408325
PRECISION 0.6922458540931644 RECALL 0.6645569620253164 FSCORE 0.6537657129919959
