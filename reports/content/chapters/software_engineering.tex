This project was primarily written in Python 3.10 utilizing Conda for dependency management. While Python is not the fastest language, it is optimized for prototyping and is capable of constructing and running neural networks, which makes it an optimal choice for this project as there was no speed or space-based performance requirements defined in either the original contest briefing, or the requirements defined for this project.

Given the exploratory nature of the project, agile development methodologies were utilized to quickly test many methods and their combinations to yield the best results. With a cycle length of one week, ideas were considered, implemented, and then evaluated to determine which methods were generating helpful results and which could be abandoned in favor of other approaches. By using this short cycle time, ideas that did not work were quickly discarded, allowing time to be spent efficiently while still allowing multiple methods to be explored. As the requirements for the project did not change cycle to cycle, determining the per-cycle requirements of any given cycle could be done by either working to optimize an existing method that showed promise or working on implementing a new method. In addition, by keeping the requirements the same week-to-week, it was possible to quickly integrate and test newly implemented techniques against their existing counterparts, as old metrics were able to be reused for comparison without re-defining new goals and re-testing each existing method on a new metric.

For the same reason, the results of previous experiments were saved and made accessible to future experiments, vastly decreasing the time spent on each experiment. This was done using methods such as using a modular pipeline architecture, pickle\cite{pickle} (python object serialization) for large datasets, and storing intermediate and reusable images to disk, instead of regenerating them for each experiment. Pickling datasets and storing images were most useful for storing the output of CNNs where the processing time was magnitudes larger than the time it took to read the information from disk. These methods also guaranteed that all experiments were performed with the same parameters by ensuring that accidental changes to an already implemented technique would not alter the results of future experiments.

Even with the protections provided by the methods described above, care was taken to maintain code quality and validity when making changes, ensuring that results could be replicated or improved on after each change was made. This also involved maintaining comments and non-code elements of the project, such as file structures and dependency versions. The latter is also being assisted by caching potentially vulnerable dependencies, such as neural network structures and weights.
