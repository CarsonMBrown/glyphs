self.hidden_size = 50
self.lstm = nn.LSTM(input_size, self.hidden_size, num_layers=3, bidirectional=True)
self.label = nn.Sequential(
    nn.Dropout(p=.1),
    nn.Linear(self.hidden_size * 2, output_size)
)
Image input directory: dataset\glyphs\eval\binarized
Reading AlexNet Data From Disk
Input Vector Size: 9216
LOADING MODEL FROM FILE
RESUMING FROM LOADED FILE
TRAINING MODEL
Image input directory: dataset\glyphs\train\binarized
Reading AlexNet Data From Disk
Training set has 113259 instances
EPOCH 1:


LOSS train 0.0 valid 1.9079378843307495
PRECISION 0.33863322146274966 RECALL 0.4368276589804231 FSCORE 0.35476387028245016
EPOCH 2:


LOSS train 0.0 valid 1.788925290107727
PRECISION 0.3775446707000045 RECALL 0.47431410951254765 FSCORE 0.3962861742721501
EPOCH 3:


LOSS train 0.0 valid 1.6888600587844849
PRECISION 0.42446982044162085 RECALL 0.5076379992773618 FSCORE 0.439790943808782
EPOCH 4:


LOSS train 0.0 valid 1.6271982192993164
PRECISION 0.469125316698643 RECALL 0.5322939249113126 FSCORE 0.47488685047163903
EPOCH 5:


LOSS train 0.0 valid 1.595702052116394
PRECISION 0.5054251840523732 RECALL 0.5488503481802655 FSCORE 0.5015207126569616
EPOCH 6:


LOSS train 0.0 valid 1.5754886865615845
PRECISION 0.5391211977412982 RECALL 0.564126141440021 FSCORE 0.5252414395462099
EPOCH 7:


LOSS train 0.0 valid 1.5668302774429321
PRECISION 0.5541793844613798 RECALL 0.5758716824333202 FSCORE 0.5409910315650065
EPOCH 8:


LOSS train 0.0 valid 1.5671831369400024
PRECISION 0.5706710555560697 RECALL 0.5823783011430823 FSCORE 0.5529506340929514
EPOCH 9:


LOSS train 0.0 valid 1.5992774963378906
PRECISION 0.586599707376885 RECALL 0.5880540911181185 FSCORE 0.5626561476148527
EPOCH 10:


LOSS train 0.0 valid 1.6052905321121216
PRECISION 0.6022566676319553 RECALL 0.5938489521744843 FSCORE 0.5743430319489506
EPOCH 11:


LOSS train 0.0 valid 1.6558914184570312
PRECISION 0.6081131072972862 RECALL 0.5931735317303902 FSCORE 0.5764796724732627
EPOCH 12:


LOSS train 0.0 valid 1.6725788116455078
PRECISION 0.6180488531307456 RECALL 0.6005672299960583 FSCORE 0.5852674938477921
EPOCH 13:


LOSS train 0.0 valid 1.7240206003189087
PRECISION 0.6212377298774201 RECALL 0.5974379188017342 FSCORE 0.5857789974869307
EPOCH 14:


LOSS train 0.0 valid 1.7731820344924927
PRECISION 0.6242466185591591 RECALL 0.5987614554592038 FSCORE 0.5881328214985009
EPOCH 15:


LOSS train 0.0 valid 1.8119075298309326
PRECISION 0.6255517501459144 RECALL 0.599529669228748 FSCORE 0.5889451793683446
EPOCH 16:


LOSS train 0.0 valid 1.8684977293014526
PRECISION 0.6263031461727367 RECALL 0.5990880797529892 FSCORE 0.5885349545440641
EPOCH 17:


LOSS train 0.0 valid 1.9043591022491455
PRECISION 0.6349161248697908 RECALL 0.5996663956773092 FSCORE 0.5930856628427554
EPOCH 18:


LOSS train 0.0 valid 1.9581453800201416
PRECISION 0.6347798765985755 RECALL 0.5987388730127448 FSCORE 0.592332122391241
EPOCH 19:LOSS train 0.0 valid 2.0065746307373047
PRECISION 0.6354256688219506 RECALL 0.5974596800683222 FSCORE 0.5920437864629423
EPOCH 20:
LOSS train 0.0 valid 2.0901291370391846
PRECISION 0.6324472913045668 RECALL 0.5942597474050717 FSCORE 0.5889731739183962
